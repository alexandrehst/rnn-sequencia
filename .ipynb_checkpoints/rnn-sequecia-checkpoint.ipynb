{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN\n",
    "\n",
    "In ths notebook, we're going to train a simple RNN to do **time-series prediction**. Given some set of input data, it should be able to generate a prediction for the next time step!\n",
    "<img src='assets/time_prediction.png' width=40% />\n",
    "\n",
    "> * First, we'll create our data\n",
    "* Then, define an RNN in PyTorch\n",
    "* Finally, we'll train our network and see how it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import resources and create data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# how many time steps/data pts are in one batch of data\n",
    "seq_length = 20\n",
    "\n",
    "# generate evenly spaced data pts\n",
    "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
    "data = np.sin(time_steps)\n",
    "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
    "\n",
    "x = data[:-1] # all but the last piece of data\n",
    "y = data[1:] # all but the first\n",
    "\n",
    "# display the data\n",
    "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
    "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 1) (17, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "#Fibonacci \n",
    "data = np.array([1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584])\n",
    "seq_length = 17\n",
    "\n",
    "#serie escada\n",
    "#data = np.array([1,2,3,2,3,4,5,6,5,6,7,8,9,8,9,10,11,12,11,12])\n",
    "#seq_length = 20\n",
    "\n",
    "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
    "\n",
    "x = data[:-1] # all but the last piece of data\n",
    "y = data[1:] # all but the first\n",
    "\n",
    "print( x.shape, y.shape)\n",
    "# display the data\n",
    "plt.plot(x, 'r.', label='input, x') # x\n",
    "plt.plot( y, 'b.', label='target, y') # y\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the RNN\n",
    "\n",
    "Next, we define an RNN in PyTorch. We'll use `nn.RNN` to create an RNN layer, then we'll add a last, fully-connected layer to get the output size that we want. An RNN takes in a number of parameters:\n",
    "* **input_size** - the size of the input\n",
    "* **hidden_dim** - the number of features in the RNN output and in the hidden state\n",
    "* **n_layers** - the number of layers that make up the RNN, typically 1-3; greater than 1 means that you'll create a stacked RNN\n",
    "* **batch_first** - whether or not the input/output of the RNN will have the batch_size as the first dimension (batch_size, seq_length, hidden_dim)\n",
    "\n",
    "Take a look at the [RNN documentation](https://pytorch.org/docs/stable/nn.html#rnn) to read more about recurrent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "        # define an RNN with specified parameters\n",
    "        # batch_first means that the first dim of the input and output will be the batch_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x (batch_size, seq_length, input_size)\n",
    "        # hidden (n_layers, batch_size, hidden_dim)\n",
    "        # r_out (batch_size, time_step, hidden_size)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # get RNN outputs\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
    "        r_out = r_out.view(-1, self.hidden_dim)  \n",
    "        \n",
    "        # get final output \n",
    "        output = self.fc(r_out)\n",
    "        \n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the input and output dimensions\n",
    "\n",
    "As a check that your model is working as expected, test out how it responds to input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  torch.Size([1, 18, 1])\n",
      "RNN(\n",
      "  (rnn): RNN(1, 10, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "Output size:  torch.Size([18, 1])\n",
      "Hidden state size:  torch.Size([2, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# test that dimensions are as expected\n",
    "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2)\n",
    "\n",
    "# generate evenly spaced, test data pts\n",
    "#time_steps = np.linspace(0, np.pi, seq_length)\n",
    "#data = np.sin(time_steps)\n",
    "#data.resize((seq_length, 1))\n",
    "\n",
    "test_input = torch.Tensor(data).unsqueeze(0) # give it a batch_size of 1 as first dimension\n",
    "print('Input size: ', test_input.size())\n",
    "\n",
    "# test out rnn sizes\n",
    "test_out, test_h = test_rnn(test_input, None)\n",
    "print(test_rnn)\n",
    "print('Output size: ', test_out.size())\n",
    "print('Hidden state size: ', test_h.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training the RNN\n",
    "\n",
    "Next, we'll instantiate an RNN with some specified hyperparameters. Then train it over a series of steps, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(1, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# decide on hyperparameters\n",
    "input_size=1 \n",
    "output_size=1\n",
    "hidden_dim=32\n",
    "n_layers=2\n",
    "\n",
    "# instantiate an RNN\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimization\n",
    "\n",
    "This is a regression problem: can we train an RNN to accurately predict the next data point, given a current data point?\n",
    "\n",
    ">* The data points are coordinate values, so to compare a predicted and ground_truth point, we'll use a regression loss: the mean squared error.\n",
    "* It's typical to use an Adam optimizer for recurrent models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss and Adam optimizer with a learning rate of 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the training function\n",
    "\n",
    "This function takes in an rnn, a number of steps to train for, and returns a trained rnn. This function is also responsible for displaying the loss and the predictions, every so often.\n",
    "\n",
    "#### Hidden State\n",
    "\n",
    "Pay close attention to the hidden state, here:\n",
    "* Before looping over a batch of training data, the hidden state is initialized\n",
    "* After a new hidden state is generated by the rnn, we get the latest hidden state, and use that as input to the rnn for the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the RNN\n",
    "def train(data, target, rnn, n_steps, print_every):\n",
    "    \n",
    "    # initialize the hidden state\n",
    "    hidden = None      \n",
    "    \n",
    "    if (train_on_gpu):\n",
    "        rnn.cuda()\n",
    "        \n",
    "    for batch_i, step in enumerate(range(n_steps)):\n",
    "        # defining the training data \n",
    "               \n",
    "        # convert data into Tensors\n",
    "        x_tensor = torch.Tensor(data).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
    "        y_tensor = torch.Tensor(target)\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            x_tensor, y_tensor = x_tensor.cuda(), y_tensor.cuda()\n",
    "            \n",
    "        # outputs from the rnn\n",
    "        \n",
    "        prediction, hidden = rnn(x_tensor, hidden)\n",
    "\n",
    "        ## Representing Memory ##\n",
    "        # make a new variable for hidden and detach the hidden state from its history\n",
    "        # this way, we don't backpropagate through the entire history\n",
    "        hidden = hidden.data\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(prediction, y_tensor)\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # perform backprop and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # display loss and predictions\n",
    "        if batch_i%print_every == 0:        \n",
    "            print('Loss: ', loss.item())\n",
    "            #plt.plot( data, 'r.') # input\n",
    "            #pred = prediction.cpu()\n",
    "            #plt.plot( pred.data.numpy().flatten(), 'b.') # predictions\n",
    "            #plt.show()\n",
    "    \n",
    "    return rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  635817.5625\n",
      "Loss:  442940.34375\n",
      "Loss:  332381.1875\n",
      "Loss:  265804.1875\n",
      "Loss:  228250.5\n",
      "Loss:  209474.625\n",
      "Loss:  201858.5\n",
      "Loss:  200167.703125\n",
      "Loss:  114305.015625\n",
      "Loss:  67668.421875\n",
      "Loss:  49127.15234375\n",
      "Loss:  99990.5234375\n",
      "Loss:  67786.046875\n",
      "Loss:  39835.93359375\n",
      "Loss:  28304.828125\n",
      "Loss:  20149.1796875\n",
      "Loss:  214684.03125\n",
      "Loss:  209070.484375\n",
      "Loss:  202824.796875\n",
      "Loss:  204922.125\n",
      "Loss:  200900.25\n",
      "Loss:  200361.078125\n",
      "Loss:  200125.140625\n",
      "Loss:  200045.53125\n",
      "Loss:  200034.0\n",
      "Loss:  200032.90625\n",
      "Loss:  200032.59375\n",
      "Loss:  200032.390625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-39a07dedeebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrained_rnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-119-07afa4576f6d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data, target, rnn, n_steps, print_every)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# outputs from the rnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m## Representing Memory ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alexandre.torres\\Anaconda3\\envs\\udacity\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-1655c0737c05>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# get RNN outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mr_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m# shape output to be (batch_size*seq_length, hidden_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mr_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alexandre.torres\\Anaconda3\\envs\\udacity\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alexandre.torres\\Anaconda3\\envs\\udacity\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 217\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the rnn and monitor results\n",
    "n_steps = 75000\n",
    "print_every = 1000\n",
    "\n",
    "dados = data[:-1]\n",
    "target = data[1:]\n",
    "\n",
    "trained_rnn = train(dados, target, rnn, n_steps, print_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series Prediction\n",
    "\n",
    "Time-series prediction can be applied to many tasks. Think about weather forecasting or predicting the ebb and flow of stock market prices. You can even try to generate predictions much further in the future than just one time step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
